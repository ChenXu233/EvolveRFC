"""å·¥ä½œæµèŠ‚ç‚¹å®šä¹‰
"""

from typing import Optional, Callable
from contextvars import ContextVar
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_core.messages import HumanMessage, SystemMessage

from ..settings import get_role_llm_config, BaseLLMConfig
from ..core.state import (
    DiscussionState,
    DiscussionEvent,
    EventType,
    add_event,
    Viewpoint,
    create_viewpoint,
    resolve_active_viewpoints,
    VIEWPOINT_POOL_LIMIT,
)
from ..core.router import default_router
from ..agents import get_role_prompt, get_reviewer_roles
from ..shared import run_review_with_viewpoint_pool, run_review_with_tools
from ..shared.tools import cleanup_tool_context


# å…¨å±€ LLM å®¢æˆ·ç«¯ç¼“å­˜
_llm_clients: dict[str, ChatOpenAI | ChatAnthropic] = {}

# === ä¸Šä¸‹æ–‡å˜é‡ç”¨äº UI å›è°ƒ ===
# è¿™äº›å˜é‡å…è®¸å¤–éƒ¨ï¼ˆå¦‚ UIï¼‰è®¾ç½®å›è°ƒå‡½æ•°ï¼ŒèŠ‚ç‚¹å†…éƒ¨ä¼šè°ƒç”¨è¿™äº›å›è°ƒ
stream_callback_var: ContextVar[Optional[Callable[[str, str], None]]] = ContextVar(
    "stream_callback", default=None
)
token_callback_var: ContextVar[Optional[Callable[[dict], None]]] = ContextVar(
    "token_callback", default=None
)
log_callback_var: ContextVar[Optional[Callable[[str], None]]] = ContextVar(
    "log_callback", default=None
)
workflow_state_callback_var: ContextVar[Optional[Callable[[str, int, dict], None]]] = ContextVar(
    "workflow_state_callback", default=None
)
finish_callback_var: ContextVar[Optional[Callable[[str, list], None]]] = ContextVar(
    "finish_callback", default=None
)
# ç”¨äºå®æ—¶åœæ­¢æ£€æŸ¥çš„æ ‡å¿—å˜é‡
_review_running_var: ContextVar[bool] = ContextVar("review_running", default=True)


def _log_message(msg: str):
    """å‘é€æ—¥å¿—æ¶ˆæ¯åˆ° UI"""
    callback = log_callback_var.get()
    if callback:
        callback(msg)


def _update_workflow_state(stage: str, round_num: int, role_data: dict = {}):
    """æ›´æ–°å·¥ä½œæµçŠ¶æ€åˆ° UI"""
    callback = workflow_state_callback_var.get()
    if callback:
        callback(stage, round_num, role_data or {})


def _on_review_start(role: str, round_num: int):
    """è¯„å®¡å¼€å§‹æ—¶è°ƒç”¨"""
    _update_workflow_state("parallel_review", round_num, {"role": role, "status": "speaking"})


def _on_review_end(role: str, round_num: int, vote: str = "å¼ƒæƒ"):
    """è¯„å®¡ç»“æŸæ—¶è°ƒç”¨"""
    _update_workflow_state("parallel_review", round_num, {"role": role, "status": "done", "vote": vote})


def _create_llm_client(
    role_name: str, config: BaseLLMConfig
) -> ChatOpenAI | ChatAnthropic:
    """æ ¹æ®é…ç½®åˆ›å»º LLM å®¢æˆ·ç«¯"""
    if not config.api_key:
        raise ValueError(f"è§’è‰² {role_name} çš„ LLM é…ç½®ç¼ºå°‘ API å¯†é’¥")

    if config.provider == "openai":
        return ChatOpenAI(
            model=config.model,
            temperature=config.temperature,
            base_url=config.base_url,
            api_key=config.api_key,
        )
    elif config.provider == "anthropic":
        return ChatAnthropic(
            model_name=config.model,
            temperature=config.temperature,
            base_url=config.base_url,
            timeout=config.timeout,
            stop=config.stop,
            api_key=config.api_key,
        )
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„ provider: {config.provider}")


def get_llm_client(role_name: str | None = None) -> ChatOpenAI | ChatAnthropic:
    """è·å– LLM å®¢æˆ·ç«¯ï¼ˆæŒ‰è§’è‰²åç§°ï¼Œæ”¯æŒç¼“å­˜ï¼‰"""
    key = role_name or "__global__"

    if key not in _llm_clients:
        if role_name:
            config = get_role_llm_config(role_name)
        else:
            config = get_role_llm_config("architect")  # ä½¿ç”¨å…¨å±€é…ç½®
        _llm_clients[key] = _create_llm_client(role_name or "architect", config)

    return _llm_clients[key]


def init_node(state: DiscussionState) -> DiscussionState:
    """åˆå§‹åŒ–èŠ‚ç‚¹"""
    return state


# === é…ç½®æ§åˆ¶ ===
# æ˜¯å¦å¯ç”¨å¤šæ®µæ€è€ƒï¼ˆå·¥å…·è°ƒç”¨ï¼‰
ENABLE_MULTI_STEP_THINKING = True


def parallel_review_node(state: DiscussionState) -> DiscussionState:
    """å¹¶è¡Œè¯„å®¡èŠ‚ç‚¹ - å¤šä¸ªè§’è‰²é¡ºåºè¯„å®¡ï¼Œæ¯ä¸ªè§’è‰²å®æ—¶æ˜¾ç¤ºè¾“å‡ºï¼Œé›†æˆè§‚ç‚¹æ± 
    
    å¦‚æœ ENABLE_MULTI_STEP_THINKING ä¸º Trueï¼Œåˆ™ä½¿ç”¨ ReAct Agent è¿›è¡Œå¤šæ®µæ€è€ƒè¯„å®¡ï¼Œ
    æ”¯æŒè°ƒç”¨å·¥å…·ï¼ˆæ–‡ä»¶è¯»å–ã€ä»£ç æœç´¢ç­‰ï¼‰æ¥è·å–æ›´å¤šä¿¡æ¯ã€‚
    """
    rfc_content = state["rfc_content"]
    current_round = state["current_round"]
    viewpoint_pool = state["viewpoint_pool"]

    # è·å–å¤–éƒ¨å›è°ƒ
    external_stream_cb = stream_callback_var.get()
    external_token_cb = token_callback_var.get()
    external_finish_cb = finish_callback_var.get()

    def stream_callback(role: str, chunk: str):
        """æµå¼è¾“å‡ºå›è°ƒ"""
        if external_stream_cb:
            external_stream_cb(role, chunk)

    # ä½¿ç”¨å¸¦è§‚ç‚¹æ± çš„è¯„å®¡é€»è¾‘
    review_results = []
    
    # åœ¨å¼€å§‹è¯„å®¡å‰æ¸…ç†å·¥å…·ä¸Šä¸‹æ–‡ï¼ˆé˜²æ­¢æ•°æ®æ®‹ç•™ï¼‰
    cleanup_tool_context()
    
    for role in get_reviewer_roles():
        # é€šçŸ¥ UI è¯„å®¡å¼€å§‹
        _on_review_start(role, current_round)
        
        # åœ¨æ¯ä¸ªè§’è‰²è¯„å®¡å¼€å§‹å‰æ¸…ç†å·¥å…·ä¸Šä¸‹æ–‡
        cleanup_tool_context()

        # åˆ›å»ºæµå¼å›è°ƒåŒ…è£…å™¨
        def make_callback(rl: str) -> Callable[[str], None]:
            def callback(chunk: str) -> None:
                stream_callback(rl, chunk)
            return callback

        role_callback = make_callback(role)

        # åˆ›å»º token å›è°ƒåŒ…è£…å™¨
        def make_token_callback(rl: str) -> Callable[[dict], None]:
            def callback(token_data: dict) -> None:
                token_data["role"] = rl
                if external_token_cb:
                    external_token_cb(token_data)
            return callback

        role_token_callback = make_token_callback(role)

        try:
            # æ ¹æ®é…ç½®é€‰æ‹©è¯„å®¡å‡½æ•°
            if ENABLE_MULTI_STEP_THINKING:
                # ä½¿ç”¨å¤šæ®µæ€è€ƒè¯„å®¡ï¼ˆReAct Agentï¼Œæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
                result = run_review_with_tools(
                    role=role,
                    content=rfc_content,
                    current_round=current_round,
                    viewpoint_pool=viewpoint_pool,
                    stream_callback=role_callback,
                    previous_results=review_results,
                    token_callback=role_token_callback,
                )
            else:
                # ä½¿ç”¨æ™®é€šè¯„å®¡ï¼ˆå•æ¬¡ LLM è°ƒç”¨ï¼‰
                result = run_review_with_viewpoint_pool(
                    role=role,
                    content=rfc_content,
                    current_round=current_round,
                    viewpoint_pool=viewpoint_pool,
                    stream_callback=role_callback,
                    previous_results=review_results,
                    token_callback=role_token_callback,
                )
            review_results.append(result)
        except Exception as e:
            review_results.append({
                "role": role,
                "content": f"è¯„å®¡å¤±è´¥ï¼š{str(e)}",
                "vote": "å¼ƒæƒ",
                "new_viewpoints": [],
            })

        # é€šçŸ¥ UI è¯„å®¡ç»“æŸ
        last_vote = review_results[-1].get("vote") if review_results else "å¼ƒæƒ"
        last_tool_calls = review_results[-1].get("tool_calls", []) if review_results else []
        _on_review_end(role, current_round, last_vote)
        
        # è°ƒç”¨ finish å›è°ƒï¼Œæ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
        if external_finish_cb:
            external_finish_cb(role, last_tool_calls)
        
        # å®æ—¶åœæ­¢æ£€æŸ¥ï¼šæ¯ä¸ªè§’è‰²è¯„å®¡å®Œæˆåç«‹å³æ£€æŸ¥åœæ­¢ä¿¡å·
        if not _review_running_var.get():
            _log_message(f"â¹ è¯„å®¡åœ¨è§’è‰² {role} å®Œæˆååœæ­¢")
            # ä¿å­˜å½“å‰çŠ¶æ€ç”¨äºæ–­ç‚¹ç»­ä¼ 
            try:
                save_workflow_state(state, "manual_stop")
                _log_message("ğŸ’¾ çŠ¶æ€å·²ä¿å­˜ï¼Œå¯ç”¨äºæ–­ç‚¹ç»­ä¼ ")
            except Exception as e:
                _log_message(f"âš ï¸ çŠ¶æ€ä¿å­˜å¤±è´¥: {e}")
            return state

    # æ”¶é›†æ‰€æœ‰æ–°äº‹ä»¶
    new_events = [
        DiscussionEvent(
            event_type=EventType.ROLE_REVIEW,
            actor=result["role"],
            content=result["content"],
            metadata={"round": current_round},
        )
        for result in review_results
    ]

    # æ”¶é›†æ‰€æœ‰æ–°è§‚ç‚¹ï¼ˆé™åˆ¶æ•°é‡ï¼‰
    new_viewpoints = []
    current_pool_size = len(state["viewpoint_pool"])
    for result in review_results:
        if current_pool_size + len(new_viewpoints) >= VIEWPOINT_POOL_LIMIT:
            break  # è§‚ç‚¹æ± å·²æ»¡
        for vp_data in result.get("new_viewpoints", []):
            if current_pool_size + len(new_viewpoints) >= VIEWPOINT_POOL_LIMIT:
                break
            new_viewpoints.append(create_viewpoint(
                content=vp_data.get("content", ""),
                evidence=vp_data.get("evidence", []),
                proposer=result["role"],
                created_round=current_round,
            ))

    # æ„å»ºæœ€ç»ˆçŠ¶æ€ï¼ˆåªè¿”å›ä¸€æ¬¡çŠ¶æ€æ›´æ–°ï¼‰
    result_state = DiscussionState(
        rfc_content=state["rfc_content"],  # ä¿æŒä¸å˜
        max_rounds=state["max_rounds"],
        current_round=state["current_round"],
        current_focus=state["current_focus"],
        consensus_points=state["consensus_points"],
        open_issues=state["open_issues"],
        viewpoint_pool=state["viewpoint_pool"] + new_viewpoints,
        resolved_viewpoints=state["resolved_viewpoints"],
        awaiting_human_input=state["awaiting_human_input"],
        human_decision=state["human_decision"],
        last_human_action=state["last_human_action"],
        timeout_count=state["timeout_count"],
        workflow_status=state["workflow_status"],
        events=state["events"] + new_events,
    )

    return result_state


def add_viewpoint_to_pool(state: DiscussionState, viewpoint: Viewpoint) -> DiscussionState:
    """å°†è§‚ç‚¹æ·»åŠ åˆ°è§‚ç‚¹æ± ï¼ˆä¸å¯å˜æ“ä½œï¼‰"""
    if len(state["viewpoint_pool"]) >= VIEWPOINT_POOL_LIMIT:
        return state  # è§‚ç‚¹æ± å·²æ»¡ï¼Œä¸æ·»åŠ 

    return DiscussionState(
        rfc_content=state["rfc_content"],
        max_rounds=state["max_rounds"],
        current_round=state["current_round"],
        current_focus=state["current_focus"],
        consensus_points=state["consensus_points"],
        open_issues=state["open_issues"],
        viewpoint_pool=state["viewpoint_pool"] + [viewpoint],
        resolved_viewpoints=state["resolved_viewpoints"],
        awaiting_human_input=state["awaiting_human_input"],
        human_decision=state["human_decision"],
        last_human_action=state["last_human_action"],
        timeout_count=state["timeout_count"],
        workflow_status=state["workflow_status"],
        events=state["events"],
    )


def vote_analyzer_node(state: DiscussionState) -> DiscussionState:
    """æŠ•ç¥¨ç»Ÿè®¡ä¸åˆ†æ­§åˆ†æèŠ‚ç‚¹"""
    events = state["events"]
    current_round = state["current_round"]

    # æ”¶é›†æœ¬è½®æŠ•ç¥¨
    vote_events = [
        e for e in events
        if e.event_type == EventType.VOTE and e.metadata.get("round") == current_round
    ]

    # è®¡ç®—æŠ•ç¥¨åˆ†å¸ƒ
    if vote_events:
        vote_results = [e.vote_result for e in vote_events if e.vote_result]
        if vote_results:
            yes_votes = vote_results.count("èµæˆ")
            no_votes = vote_results.count("åå¯¹")
            abstain_votes = vote_results.count("å¼ƒæƒ")

            # æ£€æŸ¥æ˜¯å¦éœ€è¦äººç±»ä»‹å…¥
            needs_human = default_router.should_human_intervene(state)

            # æ·»åŠ æŠ•ç¥¨ç»Ÿè®¡äº‹ä»¶
            stats_event = DiscussionEvent(
                event_type=EventType.ROUND_COMPLETE,
                actor="system",
                content=f"è½®æ¬¡ {current_round} æŠ•ç¥¨ç»Ÿè®¡ï¼šèµæˆ{yes_votes}ï¼Œåå¯¹{no_votes}ï¼Œå¼ƒæƒ{abstain_votes}",
                metadata={
                    "round": current_round,
                    "vote_summary": {"èµæˆ": yes_votes, "åå¯¹": no_votes, "å¼ƒæƒ": abstain_votes},
                    "needs_human_intervention": needs_human,
                },
            )
            state = add_event(state, stats_event)

            if needs_human:
                state["awaiting_human_input"] = True
                state["workflow_status"] = "å¾…äººç±»å†³ç­–"

    return state


def viewpoint_pool_manager_node(state: DiscussionState) -> DiscussionState:
    """è§‚ç‚¹æ± ç®¡ç†å™¨èŠ‚ç‚¹ - æ£€æŸ¥è§‚ç‚¹è§£å†³æƒ…å†µï¼Œå†³å®šä¸‹ä¸€æ­¥æµç¨‹"""
    current_round = state["current_round"]

    # æ£€æŸ¥å¹¶è§£å†³å·²è¾¾æˆå…±è¯†çš„è§‚ç‚¹
    state = resolve_active_viewpoints(state, current_round)

    # ç»Ÿè®¡è§£å†³æƒ…å†µ
    active_count = len(state["viewpoint_pool"])
    resolved_count = len(state["resolved_viewpoints"])

    # æ·»åŠ è§‚ç‚¹æ± çŠ¶æ€äº‹ä»¶
    pool_status_event = DiscussionEvent(
        event_type=EventType.ROUND_COMPLETE,
        actor="system",
        content=f"è§‚ç‚¹æ± çŠ¶æ€ï¼šæ´»è·ƒ {active_count}/{VIEWPOINT_POOL_LIMIT}ï¼Œå·²è§£å†³ {resolved_count}",
        metadata={
            "round": current_round,
            "viewpoint_pool_status": {
                "active": active_count,
                "resolved": resolved_count,
                "limit": VIEWPOINT_POOL_LIMIT,
            },
        },
    )
    state = add_event(state, pool_status_event)

    return state


def human_oversight_node(state: DiscussionState) -> DiscussionState:
    """äººç±»ç›‘ç£èŠ‚ç‚¹ - å·¥ä½œæµæš‚åœï¼Œç­‰å¾…äººç±»è¾“å…¥"""
    return state


def clerk_summary_node(state: DiscussionState) -> DiscussionState:
    """ä¹¦è®°å®˜æ€»ç»“èŠ‚ç‚¹ - æ±‡æ€»è®¨è®ºç»“æœï¼ŒåŒ…å«è§‚ç‚¹æ± ç»Ÿè®¡"""
    client = get_llm_client("clerk")
    current_round = state["current_round"]

    # æ”¶é›†æœ¬è½®äº‹ä»¶
    round_events = [
        e for e in state["events"]
        if e.metadata.get("round") == current_round
    ]

    # æ„å»ºæ€»ç»“è¾“å…¥
    input_text = f"""è¯·æ±‡æ€»ç¬¬ {current_round} è½®è®¨è®ºç»“æœã€‚

æœ¬è½®å‚ä¸è®¨è®ºçš„è§’è‰²å‘è¨€ï¼š
"""

    for event in round_events:
        if event.event_type == EventType.ROLE_REVIEW:
            input_text += f"- {event.actor}: {event.content[:500]}...\n"

    # æ·»åŠ è§‚ç‚¹æ± ç»Ÿè®¡
    active_viewpoints = state["viewpoint_pool"]
    resolved_viewpoints = state["resolved_viewpoints"]

    input_text += "\n=== è§‚ç‚¹æ± ç»Ÿè®¡ ==="
    input_text += f"\næ´»è·ƒè§‚ç‚¹æ•°ï¼š{len(active_viewpoints)}/{VIEWPOINT_POOL_LIMIT}"
    input_text += f"\nå·²è§£å†³è§‚ç‚¹æ•°ï¼š{len(resolved_viewpoints)}"

    if active_viewpoints:
        input_text += "\nå½“å‰æ´»è·ƒè§‚ç‚¹ï¼š"
        for i, vp in enumerate(active_viewpoints, 1):
            votes = f"ğŸ‘{vp.vote_count.get('èµæˆ', 0)} ğŸ‘{vp.vote_count.get('åå¯¹', 0)}"
            input_text += f"\n  {i}. [{vp.id}] {vp.content} ({votes})"

    if resolved_viewpoints:
        input_text += "\nå·²è§£å†³è§‚ç‚¹ï¼š"
        for vp in resolved_viewpoints[-3:]:  # åªæ˜¾ç¤ºæœ€è¿‘3ä¸ª
            input_text += f"\n  âœ“ [{vp.id}] {vp.content} (ç¬¬{vp.resolved_round}è½®è§£å†³)"

    input_text += f"\n\nå½“å‰å…±è¯†ç‚¹ï¼š{state['consensus_points']}"
    input_text += f"\nå¾…å†³è®®é¡¹ï¼š{state['open_issues']}"

    try:
        response = client.invoke([
            SystemMessage(content=get_role_prompt("clerk")),
            HumanMessage(content=input_text),
        ])
        response_content = response.content
        # ç¡®ä¿ content æ˜¯å­—ç¬¦ä¸²ç±»å‹
        content = str(response_content) if not isinstance(response_content, str) else response_content

        # æ·»åŠ æ¾„æ¸…äº‹ä»¶
        clarification_event = DiscussionEvent(
            event_type=EventType.CLARIFICATION,
            actor="clerk",
            content=content,
            metadata={"round": current_round},
        )
        state = add_event(state, clarification_event)

        # æ›´æ–°è½®æ¬¡
        state["current_round"] = current_round + 1

    except Exception as e:
        error_event = DiscussionEvent(
            event_type=EventType.CLARIFICATION,
            actor="clerk",
            content=f"æ±‡æ€»å¤±è´¥ï¼š{str(e)}",
            metadata={"round": current_round, "error": True},
        )
        state = add_event(state, error_event)

    return state


def timeout_checker_node(state: DiscussionState) -> DiscussionState:
    """è¶…æ—¶æ£€æµ‹èŠ‚ç‚¹"""
    if state.get("awaiting_human_input", False):
        state["timeout_count"] = state.get("timeout_count", 0) + 1
    return state


def final_report_node(state: DiscussionState) -> DiscussionState:
    """æœ€ç»ˆæŠ¥å‘Šç”ŸæˆèŠ‚ç‚¹"""
    state["workflow_status"] = "å·²å®Œæˆ"
    return state


def get_all_reviewer_roles() -> list[str]:
    """è·å–æ‰€æœ‰è¯„å®¡è€…è§’è‰²ï¼ˆä»é…ç½®åŠ¨æ€è¯»å–ï¼‰"""
    return get_reviewer_roles()


# === çŠ¶æ€ä¿å­˜/åŠ è½½åŠŸèƒ½ ===

import json
import os
from datetime import datetime
from pathlib import Path

# ä¿å­˜çŠ¶æ€æ–‡ä»¶è·¯å¾„
WORKFLOW_STATE_DIR = Path("workflow_states")


def serialize_datetime(obj):
    """åºåˆ—åŒ– datetime å¯¹è±¡"""
    if isinstance(obj, datetime):
        return obj.isoformat()
    raise TypeError(f"Type {type(obj)} not serializable")


def serialize_state(state: DiscussionState, reason: str = "manual") -> dict:
    """å°†çŠ¶æ€åºåˆ—åŒ–ä¸ºå¯ä¿å­˜çš„å­—å…¸"""
    from ..core.state import ViewpointStatus
    
    # åºåˆ—åŒ–äº‹ä»¶
    events_data = []
    for event in state.get("events", []):
        event_dict = {
            "event_type": event.event_type.value if hasattr(event.event_type, 'value') else event.event_type,
            "actor": event.actor,
            "content": event.content,
            "timestamp": serialize_datetime(event.timestamp) if hasattr(event.timestamp, 'isoformat') else str(event.timestamp),
            "metadata": event.metadata,
        }
        if hasattr(event, 'vote_result'):
            event_dict["vote_result"] = event.vote_result
        if hasattr(event, 'target_issue'):
            event_dict["target_issue"] = event.target_issue
        if hasattr(event, 'human_action'):
            event_dict["human_action"] = event.human_action
        events_data.append(event_dict)
    
    # åºåˆ—åŒ–è§‚ç‚¹æ± 
    viewpoint_pool_data = []
    for vp in state.get("viewpoint_pool", []):
        viewpoint_pool_data.append({
            "id": vp.id,
            "content": vp.content,
            "evidence": vp.evidence,
            "proposer": vp.proposer,
            "status": vp.status.value if hasattr(vp.status, 'value') else vp.status,
            "vote_count": vp.vote_count,
            "created_round": vp.created_round,
            "resolved_round": vp.resolved_round,
        })
    
    # åºåˆ—åŒ–å·²è§£å†³è§‚ç‚¹
    resolved_viewpoints_data = []
    for vp in state.get("resolved_viewpoints", []):
        resolved_viewpoints_data.append({
            "id": vp.id,
            "content": vp.content,
            "evidence": vp.evidence,
            "proposer": vp.proposer,
            "status": vp.status.value if hasattr(vp.status, 'value') else vp.status,
            "vote_count": vp.vote_count,
            "created_round": vp.created_round,
            "resolved_round": vp.resolved_round,
        })
    
    return {
        "version": "1.0",
        "saved_at": datetime.now().isoformat(),
        "save_reason": reason,
        "state": {
            "rfc_content": state.get("rfc_content", ""),
            "max_rounds": state.get("max_rounds", 10),
            "current_round": state.get("current_round", 1),
            "current_focus": state.get("current_focus", ""),
            "consensus_points": state.get("consensus_points", []),
            "open_issues": state.get("open_issues", []),
            "viewpoint_pool": viewpoint_pool_data,
            "resolved_viewpoints": resolved_viewpoints_data,
            "awaiting_human_input": state.get("awaiting_human_input", False),
            "human_decision": state.get("human_decision", None),
            "last_human_action": state.get("last_human_action", None),
            "timeout_count": state.get("timeout_count", 0),
            "workflow_status": state.get("workflow_status", "è®¨è®ºä¸­"),
            "events": events_data,
        }
    }


def deserialize_state(data: dict) -> DiscussionState:
    """ä»å­—å…¸ååºåˆ—åŒ–ä¸º DiscussionState"""
    from ..core.state import ViewpointStatus, DiscussionEvent
    
    state_data = data.get("state", data)
    
    # ååºåˆ—åŒ–äº‹ä»¶
    events = []
    for event_dict in state_data.get("events", []):
        event_type_str = event_dict.get("event_type", "role_review")
        # å°†å­—ç¬¦ä¸²è½¬æ¢ä¸º EventType æšä¸¾
        try:
            if isinstance(event_type_str, str):
                event_type = EventType(event_type_str)
            else:
                event_type = event_type_str
        except ValueError:
            event_type = EventType.ROLE_REVIEW
        
        timestamp = event_dict.get("timestamp", datetime.now())
        if isinstance(timestamp, str):
            try:
                timestamp = datetime.fromisoformat(timestamp)
            except ValueError:
                timestamp = datetime.now()
        
        event = DiscussionEvent(
            event_type=event_type,
            actor=event_dict.get("actor", "unknown"),
            content=event_dict.get("content", ""),
            timestamp=timestamp,
            metadata=event_dict.get("metadata", {}),
            vote_result=event_dict.get("vote_result", None),
            target_issue=event_dict.get("target_issue", None),
            human_action=event_dict.get("human_action", None),
        )
        events.append(event)
    
    # ååºåˆ—åŒ–è§‚ç‚¹æ± 
    viewpoint_pool = []
    for vp_dict in state_data.get("viewpoint_pool", []):
        status_str = vp_dict.get("status", "active")
        try:
            if isinstance(status_str, str):
                status = ViewpointStatus(status_str)
            else:
                status = status_str
        except ValueError:
            status = ViewpointStatus.ACTIVE
        
        vp = Viewpoint(
            id=vp_dict.get("id", ""),
            content=vp_dict.get("content", ""),
            evidence=vp_dict.get("evidence", []),
            proposer=vp_dict.get("proposer", ""),
            status=status,
            vote_count=vp_dict.get("vote_count", {"èµæˆ": 0, "åå¯¹": 0, "å¼ƒæƒ": 0}),
            created_round=vp_dict.get("created_round", 1),
            resolved_round=vp_dict.get("resolved_round", None),
        )
        viewpoint_pool.append(vp)
    
    # ååºåˆ—åŒ–å·²è§£å†³è§‚ç‚¹
    resolved_viewpoints = []
    for vp_dict in state_data.get("resolved_viewpoints", []):
        status_str = vp_dict.get("status", "resolved")
        try:
            if isinstance(status_str, str):
                status = ViewpointStatus(status_str)
            else:
                status = status_str
        except ValueError:
            status = ViewpointStatus.RESOLVED
        
        vp = Viewpoint(
            id=vp_dict.get("id", ""),
            content=vp_dict.get("content", ""),
            evidence=vp_dict.get("evidence", []),
            proposer=vp_dict.get("proposer", ""),
            status=status,
            vote_count=vp_dict.get("vote_count", {"èµæˆ": 0, "åå¯¹": 0, "å¼ƒæƒ": 0}),
            created_round=vp_dict.get("created_round", 1),
            resolved_round=vp_dict.get("resolved_round", None),
        )
        resolved_viewpoints.append(vp)
    
    return DiscussionState(
        events=events,
        rfc_content=state_data.get("rfc_content", ""),
        max_rounds=state_data.get("max_rounds", 10),
        current_round=state_data.get("current_round", 1),
        current_focus=state_data.get("current_focus", ""),
        consensus_points=state_data.get("consensus_points", []),
        open_issues=state_data.get("open_issues", []),
        viewpoint_pool=viewpoint_pool,
        resolved_viewpoints=resolved_viewpoints,
        awaiting_human_input=state_data.get("awaiting_human_input", False),
        human_decision=state_data.get("human_decision", None),
        last_human_action=state_data.get("last_human_action", None),
        timeout_count=state_data.get("timeout_count", 0),
        workflow_status=state_data.get("workflow_status", "è®¨è®ºä¸­"),
    )


def save_workflow_state(state: DiscussionState, reason: str = "manual") -> str:
    """ä¿å­˜å·¥ä½œæµçŠ¶æ€åˆ° JSON æ–‡ä»¶
    
    Args:
        state: å½“å‰å·¥ä½œæµçŠ¶æ€
        reason: ä¿å­˜åŸå› ï¼ˆ"manual" æˆ– "auto"ï¼‰
    
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    WORKFLOW_STATE_DIR.mkdir(parents=True, exist_ok=True)
    
    # ç”Ÿæˆæ–‡ä»¶åï¼šæ—¶é—´æˆ³_åŸå› .json
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"workflow_state_{timestamp}_{reason}.json"
    filepath = WORKFLOW_STATE_DIR / filename
    
    # åºåˆ—åŒ–çŠ¶æ€
    data = serialize_state(state, reason)
    
    # ä¿å­˜åˆ°æ–‡ä»¶
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return str(filepath)


def load_workflow_state(filepath: str) -> tuple[DiscussionState, str]:
    """ä» JSON æ–‡ä»¶åŠ è½½å·¥ä½œæµçŠ¶æ€
    
    Args:
        filepath: çŠ¶æ€æ–‡ä»¶è·¯å¾„
    
    Returns:
        (çŠ¶æ€å¯¹è±¡, ä¿å­˜åŸå› )
    """
    with open(filepath, "r", encoding="utf-8") as f:
        data = json.load(f)
    
    state = deserialize_state(data)
    reason = data.get("save_reason", "unknown")
    
    return state, reason


def get_latest_saved_state() -> tuple[str | None, DiscussionState | None, str | None]:
    """è·å–æœ€æ–°çš„ä¿å­˜çŠ¶æ€
    
    Returns:
        (æ–‡ä»¶è·¯å¾„, çŠ¶æ€å¯¹è±¡, ä¿å­˜åŸå› ) æˆ– (None, None, None) å¦‚æœæ²¡æœ‰ä¿å­˜çš„çŠ¶æ€
    """
    if not WORKFLOW_STATE_DIR.exists():
        return None, None, None
    
    # æŸ¥æ‰¾æ‰€æœ‰çŠ¶æ€æ–‡ä»¶
    state_files = list(WORKFLOW_STATE_DIR.glob("workflow_state_*.json"))
    if not state_files:
        return None, None, None
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
    latest_file = max(state_files, key=lambda f: f.stat().st_mtime)
    
    try:
        state, reason = load_workflow_state(str(latest_file))
        return str(latest_file), state, reason
    except Exception as e:
        _log_message(f"âš ï¸ åŠ è½½ä¿å­˜çš„çŠ¶æ€å¤±è´¥: {e}")
        return None, None, None


def clear_saved_states():
    """æ¸…é™¤æ‰€æœ‰ä¿å­˜çš„çŠ¶æ€æ–‡ä»¶"""
    if WORKFLOW_STATE_DIR.exists():
        for f in WORKFLOW_STATE_DIR.glob("workflow_state_*.json"):
            f.unlink()
        _log_message("ğŸ—‘ï¸ å·²æ¸…é™¤æ‰€æœ‰ä¿å­˜çš„çŠ¶æ€æ–‡ä»¶")
